![base](img_readme/base.png)

# üìö scrapy_books_fastapi

[![Python](https://img.shields.io/badge/Python-3.13+-blue?logo=python)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-Framework-teal?logo=fastapi)](https://fastapi.tiangolo.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-Database-336791?logo=postgresql)](https://www.postgresql.org/)
[![Docker](https://img.shields.io/badge/Docker-Containerization-2496ED?logo=docker)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

Une plateforme de **scraping**, de **gestion** et d‚Äô**analyse** de livres combinant **Scrapy**, **FastAPI** et **PostgreSQL** via **SQLModel**.

---

## Sommaire

- [üìö scrapy\_books\_fastapi](#-scrapy_books_fastapi)
  - [Sommaire](#sommaire)
  - [Fonctionnalit√©s](#fonctionnalit√©s)
  - [Architecture](#architecture)
  - [Installation](#installation)
    - [1. Cr√©er un environnement virtuel](#1-cr√©er-un-environnement-virtuel)
    - [2. Activer le `.venv`](#2-activer-le-venv)
    - [3. Installer les d√©pendances](#3-installer-les-d√©pendances)
  - [Configuration](#configuration)
  - [Lancement](#lancement)
    - [Lancer toute la plateforme](#lancer-toute-la-plateforme)
    - [Lancer uniquement certains services](#lancer-uniquement-certains-services)
      - [Lancer PostgreSQL avec Docker](#lancer-postgresql-avec-docker)
  - [Scraping et planification](#scraping-et-planification)
  - [API FastAPI](#api-fastapi)
    - [Lancer le serveur API](#lancer-le-serveur-api)
    - [Utilisation de l‚ÄôAPI](#utilisation-de-lapi)
  - [Base de donn√©es](#base-de-donn√©es)
    - [Exemple de sch√©ma de la base](#exemple-de-sch√©ma-de-la-base)
  - [](#)
  - [Auteurs et licence](#auteurs-et-licence)

---

## Fonctionnalit√©s

- **Scraping** de livres depuis [books.toscrape.com](https://books.toscrape.com) avec Scrapy.
- **Stockage** des donn√©es dans PostgreSQL via SQLModel.
- **API REST** (FastAPI) pour consulter, filtrer et analyser les livres.
- **Planification automatique** du scraping avec APScheduler.
- **Nettoyage et transformation** des donn√©es via pipelines Scrapy.
- **Analyses** statistiques sur les livres (prix, cat√©gories, etc.).
- **Configuration centralis√©e** via `.env` et Azure Key Vault (optionnel).

---

## Architecture

```bash
scrapy_books_fastapi/
‚îÇ
‚îú‚îÄ‚îÄ api/                : FastAPI (routes, sch√©mas, CRUD)
‚îú‚îÄ‚îÄ config/             : Configuration (.env, settings)
‚îú‚îÄ‚îÄ db/                 : Mod√®les SQLModel et gestion de la DB
‚îú‚îÄ‚îÄ scrapy_books/       : Projet Scrapy (spiders, pipelines, scheduler)
‚îú‚îÄ‚îÄ main.py             : Point d‚Äôentr√©e (initialisation DB, services)
‚îú‚îÄ‚îÄ runner.py           : Script de lancement (DB + scraping + API)
‚îú‚îÄ‚îÄ docker-compose.yml  : PostgreSQL via Docker
‚îú‚îÄ‚îÄ requirements.txt    : D√©pendances Python
‚îî‚îÄ‚îÄ README.md           : Ce fichier
```

---

## Installation

### 1. Cr√©er un environnement virtuel

```sh
python -m venv .venv
```

### 2. Activer le `.venv`

- Linux / macOS :
```sh
source .venv/bin/activate
```

- Windows :
```sh
.venv\Scripts\activate
```

### 3. Installer les d√©pendances

```sh
pip install -r requirements.txt
```

---

## Configuration

1. Copier l‚Äôexemple de fichier `.env` :
```sh
cp .env.example .env
```

2. Modifier les variables si besoin :

- `DB_USER`, `DB_PASSWORD`, `DB_NAME`, `DB_HOST`, `DB_PORT`
- `DOCKER_ON`, `RUN_SCRAPY`, `RUN_API`
- `AZURE_KEY_VAULT_URL` (optionnel)

> **‚ö†Ô∏è Si PostgreSQL est install√© en local, ajustez `DB_PORT` pour √©viter les conflits avec Docker.**

---

## Lancement

### Lancer toute la plateforme

Si `DOCKER_ON=True` dans `.env` et que Docker est install√©, lancez simplement :

```bash
python runner.py
```

> **‚ö†Ô∏è Par d√©faut, le scraping est planifi√© toutes les 15 minutes (pour les tests).  
> Vous pouvez modifier l‚Äôintervalle dans la fonction `start_scheduler` du fichier  
> [`scrapy_books/scheduler.py`](scrapy_books/scheduler.py) pour le passer en heures ou en jours selon vos besoins.**


Ce script :

- D√©marre PostgreSQL (si Docker activ√©)
- Attend la disponibilit√© de la base
- Cr√©e les tables via SQLModel
- Lance le scheduler Scrapy (si activ√©)
- D√©marre le serveur FastAPI (si activ√©)

### Lancer uniquement certains services

#### Lancer PostgreSQL avec Docker

```sh
docker-compose up -d
```

Sinon, assurez-vous que PostgreSQL local est lanc√© et que `.env` pointe sur la bonne base.

---

## Scraping et planification

- **Spider Scrapy** : [`books.py`](scrapy_books/scrapy_books/spiders/books.py)  
- **Planification automatique** : [`scheduler.py`](scrapy_books/scheduler.py)

Pour lancer le scraping manuellement :

```bash
cd scrapy_books
scrapy crawl books
```

---

## API FastAPI

### Lancer le serveur API

```bash
uvicorn api.main:app --reload
```

L‚ÄôAPI sera disponible sur [http://127.0.0.1:8000](http://127.0.0.1:8000)

### Utilisation de l‚ÄôAPI

- **Documentation interactive** : [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)
- **Endpoints principaux** :
  - `/books/` : liste, filtrage, recherche de livres
  - `/analytics/` : statistiques (prix moyen, nombre par cat√©gorie, etc.)
  -  `/snapshots/` : gestion et consultation des historiques de scraping
---

## Base de donn√©es

- Tables cr√©√©es automatiquement par SQLModel lors du lancement.
- Pour visualiser les relations et la structure, utilisez un outil comme **DBeaver** ou **pgAdmin**.

> Tables principales : `Book`, `BookSnapshot`,`Category`, etc., avec relations entre livres, cat√©gories et historiques de scraping.

### Exemple de sch√©ma de la base

![schemas_bdd](img_readme/books_db.png)
---

## Auteurs et licence

- Auteur principal : [benjsant](https://github.com/benjsant)
- Licence : MIT ([LICENSE](LICENSE))